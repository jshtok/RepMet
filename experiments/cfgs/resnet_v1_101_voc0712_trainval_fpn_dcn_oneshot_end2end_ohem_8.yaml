---
MXNET_VERSION: "mxnet"
output_path: "./output/fpn/voc_imagenet"
symbol: resnet_v1_101_fpn_dcn_rcnn_oneshot_v3
gpus: '4' #'0,1,2,3' #'0,1,5,7'
CLASS_AGNOSTIC: true
SCALES:
- 800
- 1280
TEST_SCALES: [[800, 1280]] # single scale testing
#TEST_SCALES: [[480, 800], [576, 900], [688, 1100], [800, 1200], [1200, 1600], [1400, 2000]] # multi-scale testing
default:
  frequent: 10
  kvstore: device
network:
  pretrained: "./data/fpn_dcn_coco" 

  pretrained_epoch: 0
  pretrained_weights_are_priority: true
  PIXEL_MEANS:
  - 103.06
  - 115.90
  - 123.15
  IMAGE_STRIDE: 32
  RCNN_FEAT_STRIDE: 16
  RPN_FEAT_STRIDE:
  - 4
  - 8
  - 16
  - 32
  - 64
  FIXED_PARAMS:
  - conv1
  - bn_conv1
  - res2
  - bn2
  - gamma
  - beta
  FIXED_PARAMS_SHARED:
  - conv1
  - bn_conv1
  - res2
  - bn2
  - res3
  - bn3
  - res4
  - bn4
  - gamma
  - beta
  ANCHOR_RATIOS:
  - 0.5
  - 1
  - 2
  ANCHOR_SCALES:
  - 8
  NUM_ANCHORS: 3
  EMBEDDING_DIM: 256
  REPS_PER_CLASS: 5
  SIGMA: 0.5
  EMBED_LOSS_ENABLED: True
  EMBED_LOSS_MARGIN: 0.5
  SOFTMAX_ENABLED: True
  REP_L2_NORM: True
  EMBED_L2_NORM: True
  SEPARABLE_REPS: False
  REPS_CLS_LOSS: False
  SEPARABLE_REPS_INIT: True
  ADDITIONAL_LINEAR_CLS_LOSS: True
dataset:
  NUM_CLASSES: 122
  balance_classes: true
  num_ex_per_class: 200
  max_num_extra_classes: 122
  dataset: PascalVOC;ImageNet
  dataset_path: "/dccstor/leonidka1/data/VOCdevkit;/dccstor/leonidka1/data/imagenet/ILSVRC"
  cls_filter_files: './data/Imagenet_LOC/Pascal_inloc_cls2id_map.pkl:./data/Imagenet_LOC/Pascal_inloc_first101_categories.txt'
  image_set: 2007_trainval+2012_trainval;train_loc
  per_category_epoch_max: 0;10
  root_path: "./data"
  test_image_set: ;val_partial
  proposal: rpn
TRAIN:
  UPDATE_REPS_VIA_CLUSTERING: true
  UPDATE_REPS_STOP_EPOCH: 3
  UPDATE_REPS_START_EPOCH: 9

  NUMEX_FOR_CLUSTERING: 200
  REPS_LR_MULT: 1 #0.01
  lr: 0.01 #0.001
  warmup_lr: 0.001
  warmup_step: 250
  warmup: true
  # lr: 0.000001
  lr_step: '4,6,20,30'
  wd: 0.0001
  begin_epoch: 0
  end_epoch: 20
  model_prefix: 'fpn_pascal_imagenet'
  # whether resume training
  RESUME: false
  # whether flip image
  FLIP: true
  # whether shuffle image
  SHUFFLE: true
  # whether use OHEM
  ENABLE_OHEM: true
  # size of images for each device, 2 for rcnn, 1 for rpn and e2e
  BATCH_IMAGES: 1
  # e2e changes behavior of anchor loader and metric
  END2END: true
  # group images with similar aspect ratio
  ASPECT_GROUPING: true
  # R-CNN
  # rcnn rois batch size
  BATCH_ROIS: -1
  BATCH_ROIS_OHEM: 512 #128
  # rcnn rois sampling params
  FG_FRACTION: 0.25
  FG_THRESH: 0.5
  BG_THRESH_HI: 0.5
  BG_THRESH_LO: 0.0
  # rcnn bounding box regression params
  BBOX_REGRESSION_THRESH: 0.5
  BBOX_WEIGHTS:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  # RPN anchor loader
  # rpn anchors batch size
  RPN_BATCH_SIZE: 256
  # rpn anchors sampling params
  RPN_FG_FRACTION: 0.5
  RPN_POSITIVE_OVERLAP: 0.7
  RPN_NEGATIVE_OVERLAP: 0.3
  RPN_CLOBBER_POSITIVES: false
  # rpn bounding box regression params
  RPN_BBOX_WEIGHTS:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  RPN_POSITIVE_WEIGHT: -1.0
  # used for end2end training
  # RPN proposal
  CXX_PROPOSAL: false
  RPN_NMS_THRESH: 0.7
  RPN_PRE_NMS_TOP_N: 12000
  RPN_POST_NMS_TOP_N: 2000
  RPN_MIN_SIZE: 0
  # approximate bounding box regression
  BBOX_NORMALIZATION_PRECOMPUTED: true
  BBOX_MEANS:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  BBOX_STDS:
  - 0.1
  - 0.1
  - 0.2
  - 0.2
TEST:
  # use rpn to generate proposal
  HAS_RPN: true
  # size of images for each device
  BATCH_IMAGES: 1
  # RPN proposal
  CXX_PROPOSAL: false
  RPN_NMS_THRESH: 0.7
  RPN_PRE_NMS_TOP_N: 12000
  RPN_POST_NMS_TOP_N: 2000
  RPN_MIN_SIZE: 0
  # RPN generate proposal
  PROPOSAL_NMS_THRESH: 0.7
  PROPOSAL_PRE_NMS_TOP_N: 20000
  PROPOSAL_POST_NMS_TOP_N: 2000
  PROPOSAL_MIN_SIZE: 0
  # RCNN nms
  NMS: 0.3
  USE_SOFTNMS: true
  SOFTNMS_THRESH: 0.6
  test_epoch: 15
  max_per_image: 100
  # soft nms
  USE_SOFTNMS: true
  SOFTNMS_THRESH: 0.6
